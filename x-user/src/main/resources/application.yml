#spring:
#  # 0-配置nacos
#  config:
#    import:
#      #      - optional:nacos:${spring.application.name}
#      - optional:nacos:x-user.yml
#  cloud:
#    nacos:
#      config:
#        namespace:
#        server-addr: 127.0.0.1:8848
#        group: ANDY_GROUP
#      discovery:
#        server-addr: 127.0.0.1:8848
server:
  port: 8083
spring:
  #  数据库配置
  datasource:
    type: com.alibaba.druid.pool.DruidDataSource
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://115.190.21.58:3306/andy_database?useUnicode=true&characterEncoding=utf8&zeroDateTimeBehavior=convertToNull&useSSL=true&serverTimezone=GMT%2B8
    username: root
    password: hy123456
    druid:
      initial-size: 5
      min-idle: 5
      max-active: 20
      max-wait: 60000
      test-on-borrow: true
      test-on-return: false
      test-while-idle: true
      #是否启用 Druid 的监控统计页面（StatViewServlet）。【访问 http://localhost:8080/druid】如 Spring Boot 3.x 需要额外配置「启动类加：@ServletComponentScan // 启用 Servlet 组件扫描（Druid 的 StatViewServlet 需要）」
      filters: stat,wall,slf4j # 启用 SQL 统计功能、防火墙、日志
      filter:
        stat:
          enabled: true
          slow-sql-millis: 1000 # 慢 SQL 阈值（毫秒）
        wall:
          enabled: true
      stat-view-servlet:
        enabled: true
        url-pattern: /druid/*
        login-username: andy
        login-password: andy
        # 关闭登录验证（不推荐生产环境使用）
        allow: 127.0.0.1  # 允许的 IP（空表示允许所有）
#        deny: 192.168.1.100 # 拒绝的 IP
#    sql:
#      init:
#        mode: always # always: 每次应用启动时都执行指定的 SQL 脚本（schema.sql 和 data.sql），即使数据库已经存在。  never: 不执行任何初始化脚本/embedded: 仅对嵌入式数据库（如 H2）执行脚本。
#        schema-locations: classpath:schema.sql
#        data-locations: classpath:data.sql
#SQL 初始化功能，用于在应用启动时自动执行 SQL 脚本以初始化数据库结构和数据

# mybatis-plus 配置 --------------------
mybatis-plus:
  mapper-locations: classpath*:/mapper/**/*.xml
  type-aliases-package: xCloud.entity
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl


#rabbitmq:-------------------------------------------------------------
rabbitmq:
  listener:
    simple:
      acknowledge-mode: manual # 手动确认消息
      concurrency: 2 # 并发消费数量
      max-concurrency: 10 # 最大并发消费数量
      retry:
        enabled: true #  开启消息重试
        max-attempts: 5 # 最大重试次数
  host: localhost
  port: 5672
  username: guest
  password: guest
  virtual-host: /andy
  publisher-returns: true
#    constants
  #  主队列-------------------------------------------------------------
  queue: andyQueue # 队列名称
  exchange: andyExchange # 交换机名称
  routing-key: andyRoutingKey  # 路由键
  #死信队列-------------------------------------------------------------
  dlx:
    exchange: a_dlx_exchange
    routing-key: a_dlx_routing_key
    queue: a_dlx_queue
  #延迟队列-------------------------------------------------------------
  delay:
    exchange: a_delay_exchange # 延迟队列交换机名称
    routing-key: a_delay_routing_key #延迟队列路由键
    queue: a_delay_queue #延迟队列
    ttl: 60000 # 延迟时间 毫秒
#    my.delay.queue：延迟队列，消息在此等待 TTL 过期。
#my.target.queue：目标队列，过期消息被路由到此队列处理。
#ttl：消息存活时间（单位：毫秒），过期后消息进入死信队列。
#-------------------------------------------------------------
#    template:
#      exchange: my_exchange
#      routing-key: my_routing_key
#      exchange-type: direct
#      default-receive-queue: my_queue

#    3-
#  langchain4j.open-ai.chat-model.api-key=${OPENAI_API_KEY}
#  langchain4j.open-ai.chat-model.model-name=gpt-4o
#  langchain4j.open-ai.chat-model.log-requests=true
#If you don't have your own OpenAI API key, don't worry.
#  You can temporarily use demo key, which we provide for free for demonstration purposes.
#  Be aware that when using the demo key, all requests to the OpenAI API need to go through our proxy, which injects the real key before forwarding your request to the OpenAI API.
#  We do not collect or use your data in any way. The demo key has a quota, is restricted to the gpt-4o-mini model,
#  and should only be used for demonstration purposes.
langchain4j:
  open-ai:
    chat-model:
      api-key: ${OPENAI_API_KEY}
      model-name: "gpt-4o-mini"
    #      log-requests: true
    #If you need an instance of a StreamingChatLanguageModel, use the streaming-chat-model instead of the chat-model properties:
#    streaming-chat-model:
#      api-key: ${OPENAI_API_KEY}
#      model-name: gpt-4
#      log-requests: true
#      log-responses: true
#      temperature: 0.7

